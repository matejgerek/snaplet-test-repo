name: Database Snapshot Capture

# TODO - schedule this to run every 2 days on Sunday, Tuesday, Thursday, and Friday
on:
  push:
    branches:
      - main

jobs:
  snapshot:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: 18.12.1
        cache: 'npm'

    - name: Cache npm
      uses: actions/cache@v3
      env:
        cache-name: cache-npm
      with:
        # npm cache files are stored in `~/.npm` on Linux/macOS
        path: |
          ~/.npm
        key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ hashFiles('**/package-lock.json') }}
        restore-keys: |
          ${{ runner.os }}-build-${{ env.cache-name }}-
          ${{ runner.os }}-build-
          ${{ runner.os }}-

    - name: Install dependencies
      # TODO: remove force if not necessary
      run: cd api && npm install --force

    - name: Capture database snapshot
      env:
        # TODO: Add env to github
        SNAPLET_SOURCE_DATABASE_URL: ${{ secrets.SNAPLET_SOURCE_DATABASE_URL }}
      run: cd api && npx snaplet snapshot capture

    - name: Find and Compress Newest Snapshot
      run: |
        # Find the newest snapshot directory in .snaplet/snapshots
        newest_snapshot_dir=$(find api/.snaplet/snapshots -type d -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d' ')
        echo "Newest snapshot directory: $newest_snapshot_dir"
        # Create a tar.gz archive of the newest snapshot
        tar -czvf production_db_snapshot.tar.gz -C "$newest_snapshot_dir" .
    
    

    - name: Upload report to CDN
      env:
        # TODO: Rename env and add to github
        BUNNY_CDN_CI_ARCHIVE_API_KEY: ${{secrets.BUNNY_CDN_CI_ARCHIVE_API_KEY}}
        BUNNY_CDN_STORAGE_ZONE_NAME: theexpert-dev-privat
      run: |
        node ${{github.workspace}}/.github/workflows/uploadSnapshotToCdn
